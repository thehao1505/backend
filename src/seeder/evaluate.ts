import { NestFactory } from '@nestjs/core'
import { AppModule } from '../app.module'
import { Model } from 'mongoose'
import { getModelToken } from '@nestjs/mongoose'
import { Logger } from '@nestjs/common'
import { Post, RecommendationLog } from '@entities'
import * as fs from 'fs'
import * as csv from 'csv-parser'
import * as path from 'path'
import { SEEDER_CONFIG } from './config'

const DATA_PATH = SEEDER_CONFIG.DATA_PATH || './data_offline_eval'
const TEST_INTERACTIONS_FILE = path.join(DATA_PATH, 'test_interactions.csv')
const SOURCE_TO_EVALUATE = SEEDER_CONFIG.SOURCE || 'hybrid'
const K = SEEDER_CONFIG.K || 10

/**
 * Helper t√≠nh P@K, R@K, AP@K, NDCG@K
 */
function calculateUserMetrics(
  recommendations: string[],
  groundTruth: Set<string>,
  K: number,
): { p_at_k: number | null; r_at_k: number | null; ap_at_k: number | null; ndcg_at_k: number | null } {
  if (groundTruth.size === 0) {
    return { p_at_k: null, r_at_k: null, ap_at_k: null, ndcg_at_k: null }
  }

  let hits = 0
  let precisionSum = 0
  let dcg = 0
  const n = Math.min(recommendations.length, K)

  for (let k = 0; k < n; k++) {
    const item = recommendations[k]
    const isRelevant = groundTruth.has(item) ? 1 : 0

    if (isRelevant) {
      hits++
      const precision_at_k_plus_1 = hits / (k + 1)
      precisionSum += precision_at_k_plus_1
    }

    // NDCG: relevance score = 1 if relevant, 0 otherwise
    // DCG = sum(relevance / log2(position + 1))
    dcg += isRelevant / Math.log2(k + 2)
  }

  const totalRelevantItems = groundTruth.size

  const p_at_k = hits / K
  const r_at_k = hits / totalRelevantItems
  const ap_at_k = precisionSum / totalRelevantItems

  // Ideal DCG: gi·∫£ s·ª≠ t·∫•t c·∫£ relevant items ·ªü top
  let idcg = 0
  for (let i = 0; i < Math.min(totalRelevantItems, K); i++) {
    idcg += 1 / Math.log2(i + 2)
  }
  const ndcg_at_k = idcg > 0 ? dcg / idcg : 0

  return { p_at_k, r_at_k, ap_at_k, ndcg_at_k }
}

/**
 * Helper ƒë·ªçc "ƒë√°p √°n" (ground truth)
 */
async function loadGroundTruth(): Promise<Map<string, Set<string>>> {
  const truthMap = new Map<string, Set<string>>()

  if (!fs.existsSync(TEST_INTERACTIONS_FILE)) {
    throw new Error(`File test_interactions.csv kh√¥ng t·ªìn t·∫°i t·∫°i: ${TEST_INTERACTIONS_FILE}`)
  }

  const stream = fs.createReadStream(TEST_INTERACTIONS_FILE).pipe(csv())

  for await (const row of stream) {
    const userId = row.userId
    const postId = row.postId

    if (!userId || !postId) continue

    if (!truthMap.has(userId)) {
      truthMap.set(userId, new Set<string>())
    }
    truthMap.get(userId)!.add(postId)
  }

  return truthMap
}

async function bootstrap() {
  const app = await NestFactory.createApplicationContext(AppModule)
  const logger = new Logger('EvaluateScript')

  const recLogModel = app.get<Model<RecommendationLog>>(getModelToken(RecommendationLog.name))

  logger.log(`=== B·∫Øt ƒë·∫ßu ƒë√°nh gi√° (Evaluate) @ K=${K} cho feed '${SOURCE_TO_EVALUATE}' ===`)

  try {
    // 1. ƒê·ªçc "ƒê√°p √°n" (Ground Truth)
    logger.log('ƒêang load ground truth t·ª´ test_interactions.csv...')
    const groundTruthMap = await loadGroundTruth()
    logger.log(`ƒê√£ t·∫£i ${groundTruthMap.size} users t·ª´ file test (ground truth).`)

    if (groundTruthMap.size === 0) {
      throw new Error('Kh√¥ng c√≥ ground truth n√†o. H√£y ch·∫°y generate_offline_eval_data.ts tr∆∞·ªõc.')
    }

    // 2. ƒê·ªçc "D·ª± ƒëo√°n" (Predictions)
    logger.log(`ƒêang load predictions t·ª´ RecommendationLog v·ªõi source='${SOURCE_TO_EVALUATE}'...`)
    const logs = await recLogModel.find({ source: SOURCE_TO_EVALUATE }).lean()

    if (logs.length === 0) {
      throw new Error(`Kh√¥ng t√¨m th·∫•y RecommendationLog cho source='${SOURCE_TO_EVALUATE}'. B·∫°n ƒë√£ ch·∫°y script "predict.ts" ch∆∞a?`)
    }
    logger.log(`ƒê√£ t·∫£i ${logs.length} d·ª± ƒëo√°n t·ª´ RecommendationLog.`)

    // Debug: Ki·ªÉm tra m·ªôt v√†i recommendations v√† ground truth
    if (logs.length > 0) {
      const sampleLog = logs.find(l => l.shownPostIds && l.shownPostIds.length > 0) || logs[0]
      const sampleUserId = sampleLog.userId.toString()
      const samplePredictions = (sampleLog.shownPostIds || []).map(id => id.toString())
      const sampleTruth = groundTruthMap.get(sampleUserId) || new Set<string>()

      logger.log(`\n[DEBUG] Sample User: ${sampleUserId}`)
      logger.log(`  Predictions count: ${samplePredictions.length}`)
      logger.log(`  Ground Truth count: ${sampleTruth.size}`)
      if (samplePredictions.length > 0) {
        logger.log(`  Predictions (first 5): ${samplePredictions.slice(0, 5).join(', ')}`)
      }
      if (sampleTruth.size > 0) {
        logger.log(`  Ground Truth (first 5): ${Array.from(sampleTruth).slice(0, 5).join(', ')}`)
      }

      // Ki·ªÉm tra format ID
      if (samplePredictions.length > 0 && sampleTruth.size > 0) {
        const firstPred = samplePredictions[0]
        const firstTruth = Array.from(sampleTruth)[0]
        logger.log(`  Sample prediction ID: "${firstPred}" (length: ${firstPred.length})`)
        logger.log(`  Sample truth ID: "${firstTruth}" (length: ${firstTruth.length})`)
        logger.log(`  IDs match format: ${firstPred.length === firstTruth.length}`)
        logger.log(`  Direct match test: ${sampleTruth.has(firstPred)}`)
      }

      // ƒê·∫øm s·ªë logs r·ªóng
      const emptyLogs = logs.filter(l => !l.shownPostIds || l.shownPostIds.length === 0).length
      logger.log(`  Logs r·ªóng (kh√¥ng c√≥ recommendations): ${emptyLogs}/${logs.length}`)
    }

    const metrics = {
      precisionAtK: [] as number[],
      recallAtK: [] as number[],
      averagePrecisionAtK: [] as number[],
      ndcgAtK: [] as number[],
    }

    // Metrics m·ªõi: Coverage, Diversity, Novelty
    const allRecommendedPostIds = new Set<string>()
    const allGroundTruthPostIds = new Set<string>()
    const userCategoryDiversity: number[] = [] // Diversity score cho m·ªói user
    const userAuthorDiversity: number[] = [] // Author diversity cho m·ªói user

    let usersWithHits = 0
    let usersEvaluated = 0

    // Load post details ƒë·ªÉ t√≠nh diversity (c·∫ßn categories v√† authors)
    const postModel = app.get<Model<Post>>(getModelToken(Post.name))
    const allPostIds = new Set<string>()
    logs.forEach(log => {
      log.shownPostIds.forEach(id => allPostIds.add(id.toString()))
    })
    groundTruthMap.forEach(truthSet => {
      truthSet.forEach(id => allPostIds.add(id))
    })

    const postsMap = new Map<string, any>()
    if (allPostIds.size > 0) {
      const posts = await postModel
        .find({ _id: { $in: Array.from(allPostIds) } })
        .select('categories author')
        .lean()
      posts.forEach(post => {
        postsMap.set(post._id.toString(), post)
      })
    }

    // 3. So s√°nh
    const zeroPrecisionUsers: Array<{ userId: string; predictions: string[]; truth: string[]; overlap: number }> = []

    for (const log of logs) {
      const userId = log.userId.toString()
      const predictions = log.shownPostIds.map(id => id.toString())
      const truth = groundTruthMap.get(userId) || new Set<string>()

      // Ch·ªâ ƒë√°nh gi√° user c√≥ trong b·ªô test
      if (truth.size === 0) {
        continue
      }

      usersEvaluated++

      // Debug: Track users v·ªõi zero precision ƒë·ªÉ ph√¢n t√≠ch
      const overlap = predictions.filter(p => truth.has(p)).length
      if (overlap === 0 && zeroPrecisionUsers.length < 5) {
        zeroPrecisionUsers.push({
          userId,
          predictions: predictions.slice(0, 10),
          truth: Array.from(truth).slice(0, 10),
          overlap: 0,
        })
      }

      // T√≠nh coverage: th√™m t·∫•t c·∫£ recommended posts
      predictions.forEach(postId => allRecommendedPostIds.add(postId))
      truth.forEach(postId => allGroundTruthPostIds.add(postId))

      // T√≠nh diversity cho user n√†y
      const categories = new Set<string>()
      const authors = new Set<string>()
      predictions.forEach(postId => {
        const post = postsMap.get(postId)
        if (post) {
          if (post.categories && Array.isArray(post.categories)) {
            post.categories.forEach((cat: string) => categories.add(cat))
          }
          if (post.author) {
            authors.add(post.author.toString())
          }
        }
      })

      // Diversity = s·ªë unique categories / s·ªë posts (normalized)
      const categoryDiversity = predictions.length > 0 ? categories.size / Math.min(predictions.length, 10) : 0
      const authorDiversity = predictions.length > 0 ? authors.size / Math.min(predictions.length, 10) : 0
      userCategoryDiversity.push(categoryDiversity)
      userAuthorDiversity.push(authorDiversity)

      const { p_at_k, r_at_k, ap_at_k, ndcg_at_k } = calculateUserMetrics(predictions, truth, K)

      if (p_at_k !== null) {
        metrics.precisionAtK.push(p_at_k)
        metrics.recallAtK.push(r_at_k)
        metrics.averagePrecisionAtK.push(ap_at_k)
        if (ndcg_at_k !== null) {
          metrics.ndcgAtK.push(ndcg_at_k)
        }

        if (p_at_k > 0) {
          usersWithHits++
        }
      }
    }

    // 4. T√≠nh trung b√¨nh
    if (usersEvaluated === 0) {
      throw new Error('Kh√¥ng c√≥ user n√†o trong log kh·ªõp v·ªõi ground truth.')
    }

    const mean = (arr: number[]) => (arr.length > 0 ? arr.reduce((a, b) => a + b, 0) / arr.length : 0)

    const meanPrecision = mean(metrics.precisionAtK)
    const meanRecall = mean(metrics.recallAtK)
    const MAP = mean(metrics.averagePrecisionAtK)
    const meanNDCG = mean(metrics.ndcgAtK)

    // Th·ªëng k√™ th√™m
    const avgGroundTruthSize =
      groundTruthMap.size > 0 ? Array.from(groundTruthMap.values()).reduce((sum, set) => sum + set.size, 0) / groundTruthMap.size : 0

    const avgRecommendationsPerUser = logs.length > 0 ? logs.reduce((sum, log) => sum + log.shownPostIds.length, 0) / logs.length : 0

    logger.log('\n--- üìä K·∫æT QU·∫¢ ƒê√ÅNH GI√Å üìä ---')
    logger.log(`Feed ƒë∆∞·ª£c ƒë√°nh gi√°:           ${SOURCE_TO_EVALUATE}`)
    logger.log(`K (Top-K):                    ${K}`)
    logger.log(`S·ªë user ƒë∆∞·ª£c ƒë√°nh gi√°:      ${usersEvaluated}`)
    logger.log(`S·ªë user c√≥ hits:              ${usersWithHits} (${((usersWithHits / usersEvaluated) * 100).toFixed(2)}%)`)
    logger.log(`Avg ground truth size:        ${avgGroundTruthSize.toFixed(2)}`)
    logger.log(`Avg recommendations/user:   ${avgRecommendationsPerUser.toFixed(2)}`)
    logger.log('')
    logger.log(`Mean Precision@${K}:          ${(meanPrecision * 100).toFixed(4)}%`)
    logger.log(`Mean Recall@${K}:             ${(meanRecall * 100).toFixed(4)}%`)
    logger.log(`MAP@${K}:                     ${(MAP * 100).toFixed(4)}%`)
    logger.log(`Mean NDCG@${K}:                ${(meanNDCG * 100).toFixed(4)}%`)

    // T√≠nh Coverage: % posts trong ground truth ƒë∆∞·ª£c recommend √≠t nh·∫•t 1 l·∫ßn
    const coverage =
      allGroundTruthPostIds.size > 0
        ? (Array.from(allGroundTruthPostIds).filter(id => allRecommendedPostIds.has(id)).length / allGroundTruthPostIds.size) * 100
        : 0

    // T√≠nh Catalog Coverage: % unique posts ƒë∆∞·ª£c recommend
    const totalPostsInCatalog = allPostIds.size
    const catalogCoverage = totalPostsInCatalog > 0 ? (allRecommendedPostIds.size / totalPostsInCatalog) * 100 : 0

    // T√≠nh Diversity: trung b√¨nh diversity scores
    const meanCategoryDiversity = mean(userCategoryDiversity)
    const meanAuthorDiversity = mean(userAuthorDiversity)
    const meanDiversity = (meanCategoryDiversity + meanAuthorDiversity) / 2

    logger.log('')
    logger.log('--- üìà METRICS M·ªöI üìà ---')
    logger.log(`Coverage (Ground Truth):      ${coverage.toFixed(4)}%`)
    logger.log(`Catalog Coverage:              ${catalogCoverage.toFixed(4)}%`)
    logger.log(`Mean Category Diversity:       ${(meanCategoryDiversity * 100).toFixed(4)}%`)
    logger.log(`Mean Author Diversity:         ${(meanAuthorDiversity * 100).toFixed(4)}%`)
    logger.log(`Mean Overall Diversity:        ${(meanDiversity * 100).toFixed(4)}%`)

    // Ph√¢n t√≠ch chi ti·∫øt h∆°n
    const precisionDistribution = {
      zero: metrics.precisionAtK.filter(p => p === 0).length,
      low: metrics.precisionAtK.filter(p => p > 0 && p < 0.1).length,
      medium: metrics.precisionAtK.filter(p => p >= 0.1 && p < 0.3).length,
      high: metrics.precisionAtK.filter(p => p >= 0.3).length,
    }

    logger.log('\n--- Ph√¢n b·ªë Precision ---')
    logger.log(`  Zero (0%):     ${precisionDistribution.zero} (${((precisionDistribution.zero / usersEvaluated) * 100).toFixed(2)}%)`)
    logger.log(`  Low (0-10%):    ${precisionDistribution.low} (${((precisionDistribution.low / usersEvaluated) * 100).toFixed(2)}%)`)
    logger.log(
      `  Medium (10-30%): ${precisionDistribution.medium} (${((precisionDistribution.medium / usersEvaluated) * 100).toFixed(2)}%)`,
    )
    logger.log(`  High (>30%):    ${precisionDistribution.high} (${((precisionDistribution.high / usersEvaluated) * 100).toFixed(2)}%)`)

    // Ph√¢n t√≠ch theo s·ªë l∆∞·ª£ng ground truth
    const usersByGTSize = {
      small: 0, // 1-2 items
      medium: 0, // 3-5 items
      large: 0, // >5 items
    }

    for (const [userId, truthSet] of groundTruthMap.entries()) {
      const log = logs.find(l => l.userId.toString() === userId)
      if (!log) continue

      const size = truthSet.size
      if (size <= 2) usersByGTSize.small++
      else if (size <= 5) usersByGTSize.medium++
      else usersByGTSize.large++
    }

    logger.log('\n--- Ph√¢n b·ªë Ground Truth Size ---')
    logger.log(`  Small (1-2):    ${usersByGTSize.small}`)
    logger.log(`  Medium (3-5):   ${usersByGTSize.medium}`)
    logger.log(`  Large (>5):     ${usersByGTSize.large}`)

    // Debug: Hi·ªÉn th·ªã sample users v·ªõi zero precision
    if (zeroPrecisionUsers.length > 0) {
      logger.log('\n--- üîç DEBUG: Sample Users v·ªõi Zero Precision ---')
      for (const user of zeroPrecisionUsers.slice(0, 3)) {
        logger.log(`\n  User: ${user.userId}`)
        logger.log(`    Predictions (first 5): ${user.predictions.slice(0, 5).join(', ')}`)
        logger.log(`    Ground Truth (first 5): ${user.truth.slice(0, 5).join(', ')}`)
        logger.log(`    Overlap: ${user.overlap}`)
      }
      logger.log(`\n  üí° G·ª£i √Ω: Ki·ªÉm tra xem recommendations c√≥ match v·ªõi user preferences kh√¥ng`)
      logger.log(`  üí° C√≥ th·ªÉ c·∫ßn: TƒÉng candidate pool, c·∫£i thi·ªán scoring weights, ho·∫∑c c·∫£i thi·ªán fallback strategy`)
    }

    logger.log('\n--- ‚úÖ Ho√†n t·∫•t ƒë√°nh gi√° ‚úÖ ---')
  } catch (error) {
    logger.error('‚ùå ‚ùå ‚ùå K·ªãch b·∫£n th·∫•t b·∫°i:', error)
    throw error
  } finally {
    await app.close()
  }
}

bootstrap()
